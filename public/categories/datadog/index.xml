<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/">
  <channel>
    <title>Datadog on Daniel Schaaff</title>
    <link>http://localhost:1313/categories/datadog/</link>
    <description>Recent content in Datadog on Daniel Schaaff</description>
    <generator>Hugo -- 0.147.4</generator>
    <language>en</language>
    <lastBuildDate>Wed, 29 Aug 2018 03:45:14 +0000</lastBuildDate>
    <atom:link href="http://localhost:1313/categories/datadog/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Monitoring Creation of Log Files in s3</title>
      <link>http://localhost:1313/posts/2018/monitoring-creation-of-log-files-in-s3/</link>
      <pubDate>Wed, 29 Aug 2018 03:45:14 +0000</pubDate>
      <guid>http://localhost:1313/posts/2018/monitoring-creation-of-log-files-in-s3/</guid>
      <description>&lt;p&gt;I manage several apps that write various pieces of data to the local file system and rely on Fluentd to ship them to s3. There is solid monitoring around the fluentd aggregator process, but I wanted better visibility and alerting when things aren’t written to s3 as expected.&lt;/p&gt;
&lt;p&gt;The solution I came up with was a &lt;a href=&#34;https://github.com/dschaaff/datadog-checks&#34;&gt;custom Datadog check&lt;/a&gt;. The files I am monitoring are written into a bucket named something like &lt;code&gt;example-logs/data/event-files/year/month/day&lt;/code&gt;. A new path is set up in the s3 bucket for the current day’s date, e.g. &lt;code&gt;logs/data/example-log/2018/08/15&lt;/code&gt; each day. The Datadog check sends the count of objects in the current date’s directory as a gauge. You can then monitor that objects are created each day as expected and at a normal rate.&lt;/p&gt;</description>
    </item>
  </channel>
</rss>
